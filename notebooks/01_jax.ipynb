{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6623b1e1",
   "metadata": {},
   "source": [
    "### CRC183 Summer School \"Machine Learning in Condensed Matter Physics\"\n",
    "# Hands-on session: Building deep learning models with JAX/Flax\n",
    "\n",
    "## Installing JAX, NetKet & Co.\n",
    "\n",
    "In today's session you will learn about basics of JAX and the Netket library. Installing NetKet is relatively straightforward and it will automatically install JAX as a dependency. \n",
    "\n",
    "For this Tutorial, **if you are running it locally on your machine**, we recommend that you create a clean virtual environment and install NetKet within: \n",
    "\n",
    "```bash\n",
    "python3 -m venv netket\n",
    "source netket/bin/activate\n",
    "pip install --pre netket\n",
    "```\n",
    "\n",
    "If you are wondering why we use the flag ```--pre``` it is because today we will be working on a pre (beta) release of version 3.0. \n",
    "\n",
    "**If you are on Google Colab**, run the following cell to install the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a7a880",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --pre -U netket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf2d586",
   "metadata": {},
   "source": [
    "You can check that the installation was succesfull doing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7bc09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce9661c",
   "metadata": {},
   "source": [
    "## JAX\n",
    "\n",
    "[JAX](https://github.com/google/jax) is a Python library that provides essential functionality for deep learning applications, namely\n",
    "\n",
    "* **automatic differentiation**\n",
    "* **vectorization**\n",
    "* **just-in-time compilation** to GPU/TPU accelerators\n",
    "\n",
    "It is being developed \"for high-performance machine learning research\" and as such well suited for physics applications. The abovementioned features are implemented in a system of composable function transformations that \"process\" Python functions.\n",
    "\n",
    "## `jax.numpy`\n",
    "\n",
    "The function transformations of JAX rely on functions being written in a \"JAX-intellegible\" form. For this purpose the `jax.numpy` sub-module emulates almost the whole NumPy functionality. When using JAX, any array operations should be written using `jax.numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fdb8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3469dcf2",
   "metadata": {},
   "source": [
    "The basic object is the `jnp.array`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2e9405",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = jnp.array([1,2,3])\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3e521b",
   "metadata": {},
   "source": [
    "NumPy arrays and `jax.numpy` arrays can be converted into each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abd1607",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.array(arr)\n",
    "type(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b75b4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(jnp.array(np_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff7d4ae",
   "metadata": {},
   "source": [
    "Most NumPy functions have an equivalent in `jax.numpy`, e.g. `sum()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0b0863",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jnp.sum(arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d715676f",
   "metadata": {},
   "source": [
    "## JAX random numbers\n",
    "\n",
    "JAX implements a pseudo-random number generator (PRNG) in the `jax.random` submodule. The JAX PRNG handles the state of the PRNG explicitly in the form of *keys* that have to be passed around, and which can be split in order to fork the PRNG state into new PRNGs.\n",
    "\n",
    "Let's generate an initial key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc7a9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=1234\n",
    "key = jax.random.PRNGKey(seed)\n",
    "print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119fcba0",
   "metadata": {},
   "source": [
    "Any function in `jax.random` that generates random numbers takes a key as argument, e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c171905",
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.random.normal(key, (3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3bd8d2",
   "metadata": {},
   "source": [
    "Passing the same key results in the same set of random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60df1d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.random.normal(key, (3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d760d559",
   "metadata": {},
   "source": [
    "To get a different sequence of random numbers, we need to generate a new key by splitting the original one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebbcbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, newkey = jax.random.split(key)\n",
    "\n",
    "jax.random.normal(newkey, (3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcef25ab",
   "metadata": {},
   "source": [
    "## Warning of \"sharp edges\" in JAX\n",
    "\n",
    "The ability to perform the various function transformations imposes a number of **constraints on how those functions are written**. Before diving deeper into the JAX library, reading [\"JAX - the sharp bits\"](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html), which summarizes the main pitfalls when working with it, is highly recommended.\n",
    "\n",
    "The most important points are\n",
    "\n",
    " * **Pure functions**: All input data have to be passed to the function as arguments and all results given as return values. Don't work with global variables or side effects. Some workarounds are needed to reconcile JAX with object-oriented code.\n",
    " * **Control flow** needs some care. Replace Python ``for``-loops or ``if``-branching with primitives from the ``jax.lax`` sub-module, [see documentation](https://jax.readthedocs.io/en/latest/jax.lax.html#control-flow-operators).\n",
    " * **JAX arrays are immutable**: As a python programmer you are used to updating array elements with ``array[13,:]=3.1415``. Unfortunately, this does not work with JAX arrays. Instead you need to use JAX's indexed update functionality, e.g. in this case ``array.at[13, :].set(3.1415)``. [See the documentation for details](https://jax.readthedocs.io/en/latest/jax.ops.html#indexed-update-operators)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f56aa0",
   "metadata": {},
   "source": [
    "## Flax\n",
    "\n",
    "[Flax](https://github.com/google/flax) builds on JAX and provides a framework to easily define arbitrary deep learning models very similar to PyTorch. Moreover, typical building blocks of deep learning models are already implemented in the library.\n",
    "\n",
    "As an example, let's define a simple feed-forward network with a single layer. It consists of a dense layer, i.e., an affine-linear transformation of the input followed by a $\\text{ReLU}(\\cdot)$ non-linearity giving the *activations*. Additionally, we include a reduction operation to obtain a single number as output, namely the sum of the activations:\n",
    "\n",
    "$$\n",
    "f_{W,b}(x) = \\sum_i \\text{ReLU}(W_{i,j}x_j+b_i)\n",
    "$$\n",
    "\n",
    "In Flax this neural network can be implemented as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47107e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax.linen as nn\n",
    "\n",
    "class MyFFN(nn.Module):\n",
    "    num_neurons: int\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        \n",
    "        z = nn.Dense(self.num_neurons)(x) # affine-linear transformation of the input\n",
    "        a = nn.relu(z) # non-linearity\n",
    "        \n",
    "        return jnp.sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29814073",
   "metadata": {},
   "source": [
    "The code above shows the basic syntax to define a custom model in Flax. A Flax model is a class that inherits from the abstract `flax.linen.Module` class. As part of it we have to implement a `__call__` method that defines how the network is evaluated for a given input.\n",
    "\n",
    "In the example the `__call__` method is decorated with `@nn.compact`, because we are using the compact definition of a Flax model. This is possible for simple models where we do not have to specify an additional setup procedure for the initialization of the model. For more complex models a `setup` method can be defined for the initialization; in that case the `@nn.compact` decorator has to be dropped.\n",
    "\n",
    "In addition, we defined the data field `num_neurons`. The data fields of the model class are initialized by the constructor and they can contain the hyperparameters of the model.\n",
    "\n",
    "Finally, we use some of the pre-implemented building blocks, namely the `nn.Dense` layer for the affine-linear transformation and the activation function `nn.relu`.\n",
    "\n",
    "Through the `nn.Module` base class our `MyFFN` class will have further methods that allow us to deal with the model. Below we will learn about `init` for parameter intialization and `apply` for the evaluation.\n",
    "\n",
    "Now we can create an instance of this class, passing a value for the `num_neurons` hyperparameter to the constructor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d4cd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MyFFN(num_neurons=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2307c4fa",
   "metadata": {},
   "source": [
    "Before we can work with this model, we also need to get an initial set of parameters. For this purpose we have to call the model's `init` method, which takes an `jax.random.PRNGKey` and an exemplary input datum as arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7a9f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_input = jax.random.normal(jax.random.PRNGKey(4321), (28*28,))\n",
    "params = net.init(jax.random.PRNGKey(1234), example_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932a1895",
   "metadata": {},
   "source": [
    "The set of parameters is returned in the form of a tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44faec83",
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251ce580",
   "metadata": {},
   "source": [
    "Now we can evaluate our neural network on the input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53318b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.apply(params, example_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d7723f",
   "metadata": {},
   "source": [
    "To define models that don't rely on Flax's standard building blocks, parameters can be declared explicitly with the ``self.param`` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe8d000",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyFFNfromScratch(nn.Module):\n",
    "    num_neurons: int\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        \n",
    "        W = self.param('W',\n",
    "                    nn.initializers.lecun_normal(), # Initialization function\n",
    "                    (self.num_neurons, x.shape[-1]))  # shape of the matrix\n",
    "        \n",
    "        b = self.param('b', nn.initializers.zeros, (self.num_neurons,))\n",
    "        \n",
    "        z = jnp.dot(W,x) + b # affine-linear transformation of the input\n",
    "        a = nn.relu(z) # non-linearity\n",
    "        \n",
    "        return jnp.sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de80775b",
   "metadata": {},
   "source": [
    "Initialization and evaluation is identical to the example above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e62eaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = MyFFNfromScratch(num_neurons=123)\n",
    "params1 = net1.init(jax.random.PRNGKey(1234), example_input)\n",
    "net1.apply(params1, example_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29334407",
   "metadata": {},
   "source": [
    "We can check, that in the ``params1`` dictionary we see our custom parameter names together with the random initial values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a9bf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "params1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd4f50f-8f52-479f-96fc-353795b4cf76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95ce2328-1730-4cd9-b4d9-b94e69ed12c5",
   "metadata": {},
   "source": [
    "# Function transformations in JAX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659826d3-8184-4777-bfa3-204b597e8a51",
   "metadata": {},
   "source": [
    "<h3 style=\"color: red\">This part of the JAX notebook is not required for getting started with NetKet.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea074596-78cb-4c2a-b616-be741b64ccac",
   "metadata": {},
   "source": [
    "In the following part, we introduce some essential elements that make JAX so useful. In particular, we will look at 'just-in-time' compilation with `jit`, automatic differentation with `grad`, and vectorization with `vmap`. These are useful to know not only for working with neural networks, but more generally (see e.g. the neural_schrodinger and coulomb_gas notebooks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702cfe93-fe16-4450-a34e-b931445d8ebc",
   "metadata": {},
   "source": [
    "## Just-in-time compilation with `jax.jit`\n",
    "\n",
    "With just-in-time compilation JAX can generate compiled versions of Python functions that run on GPUs/TPUs if available and otherwise on the CPU. This can yield substantial performance gains.\n",
    "\n",
    "Let's define an example function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45e9427e-589f-416d-b3e1-c4fdcabe851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x*x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe01897-4fe0-4207-b5f7-2efc03144b9c",
   "metadata": {},
   "source": [
    "Now we can get a compiled version of the function with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52a2003b-b3d5-4887-b8ee-4d87a7a95d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_jitd = jax.jit(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2da40220-2a1a-4196-b52c-91e87cd07a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray(0, dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(3)-f_jitd(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84272b45-c5c7-4d01-b2fa-84b2f0f565bb",
   "metadata": {},
   "source": [
    "#### Remarks\n",
    "* The function returned by `jax.jit` is only compiled at the point when it is first called.\n",
    "* The function is compiled for fixed shapes of the arguments that are given at the first call. Therefore, the first call can take substantially longer than subsequent calls.\n",
    "* Calling a compiled function with different argument shapes will cause re-compilation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a508709-3bc3-42b5-a3b2-e9603c4590ce",
   "metadata": {},
   "source": [
    "## Automatic differentiation with `jax.grad`\n",
    "\n",
    "`jax.grad` returns a function that computes the gradient of the input function with respect to its arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "898a5e16-b3da-46d4-9017-6bc782f9f509",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = jax.grad(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82771fd6",
   "metadata": {},
   "source": [
    "Since JAX function transformations are composable, we can also easily compute higher order derivatives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2d8d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = jax.grad(jax.grad(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254cdb1d",
   "metadata": {},
   "source": [
    "Let's convince ourselves, that JAX's gradients are correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0341a69-1f64-41e2-ba8c-4acebee4bbee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x_list = jnp.arange(0,1.\n",
    "                    1,.1)\n",
    "f_values = jnp.array([f(x) for x in x_list])\n",
    "df_values = jnp.array([df(x) for x in x_list])\n",
    "ddf_values = jnp.array([ddf(x) for x in x_list])\n",
    "\n",
    "plt.plot(x_list, f_values, label=\"f(x)\")\n",
    "plt.plot(x_list, df_values, label=\"f'(x)\")\n",
    "plt.plot(x_list, ddf_values, label=\"f''(x)\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12617e11-eca6-42d0-933f-b6cb2bb1a9a9",
   "metadata": {},
   "source": [
    "## Vectorization with `jax.vmap`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4228232e",
   "metadata": {},
   "source": [
    "For a given function that operates on some input data, `jax.vmap` returns a vectorized version of that function, that applies the original function *element-wise* to vectors of input data.\n",
    "\n",
    "This is very natural, since one focus of JAX is ultimately the execution of the Python code on GPUs. On the other hand, JAX inherits some of the Python issues with for-loops. Vectorizing an operation is often a good alternative to writing a for-loop.\n",
    "\n",
    "Let's vectorize our gradient function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a89bf07-0c99-46b5-82f3-9bda68b796b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vmapd = jax.vmap(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c7a9fd",
   "metadata": {},
   "source": [
    "Now we can directly call `df_vmapd` on a list of input values and we do not need any more the construction `jnp.array([df(x) for x in x_list])` that we used above.\n",
    "\n",
    "Let's check that the output of both versions is identical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfd831e9-67c5-47b6-87b9-485a76f48d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_list = jnp.arange(0,1.1,.1)\n",
    "\n",
    "# The vmap-ed function enables us to evaluate gradients directly on the list of x-values\n",
    "df_values_with_vmap = df_vmapd(x_list)\n",
    "\n",
    "df_values = jnp.array([df(x) for x in x_list])\n",
    "\n",
    "df_values - df_values_with_vmap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
