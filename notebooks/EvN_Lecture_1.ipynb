{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583a057a-8f2b-49f8-829b-3df2f9acb3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell, if you are running the notebook on Google Colab:\n",
    "!git clone https://github.com/CRC183-summer-school/school_2021.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e4be9ead-0f43-4a13-a6e1-6d7fdd4dc033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everything we need from JAX\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap, random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9632d9-3e89-452e-b071-f9f1913b0224",
   "metadata": {},
   "source": [
    "## Activation functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5b13e3a-5c43-4fac-bdc0-b1d5c874138b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return jnp.maximum(0, x)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+jnp.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167a3158-7210-4898-872d-f9188aa1f756",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "848b8b97-c284-48f8-9216-5496c9a9e96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The key for our random number generator, we need this because JAX will distribute the calculation\n",
    "key = random.PRNGKey(0)\n",
    "\n",
    "def initialize_network_params(layer_sizes):\n",
    "    # Get a random key for each layer\n",
    "    keys = random.split(key, len(layer_sizes))\n",
    "    \n",
    "    parameters = []\n",
    "    for i in range(len(layer_sizes)-1):\n",
    "        parameters.append( [random.normal(keys[i], (layer_sizes[i+1], layer_sizes[i])), # The weight matrix\n",
    "                            random.normal(keys[i], (layer_sizes[i+1],)) ]) # The bias\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "61cbedde-7959-486f-9392-0a8dac1c95e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [50, 10, 2]\n",
    "neural_network_parameters = initialize_network_params(layer_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a18d475f-13b7-42af-b843-92d60b636373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sample(params, sample):\n",
    "    activations = sample\n",
    "    \n",
    "    # Feed through the network, layer by layer\n",
    "    for weights, biases in params:\n",
    "        outputs = jnp.dot(weights, activations) + biases\n",
    "        activations = sigmoid(outputs)\n",
    "        \n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "7b4cb472-c494-4b2e-bd02-46619f46e6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([0.7025618, 0.7088518], dtype=float32)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sample(neural_network_parameters, np.zeros(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f037979-9e91-4b96-bdeb-2d4fe94f2de4",
   "metadata": {},
   "source": [
    "## The Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "744a3f0a-b318-4f3c-bad3-4d7505f78648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_for_sample(params, sample, target):\n",
    "    pred = predict_sample(params, sample)\n",
    "    return jnp.mean( (pred - target)**2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "42945a0e-1472-4158-aa39-65b2d7c8bbde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(0.2954702, dtype=float32)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_for_sample(neural_network_parameters, np.zeros(50), np.array([1,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a9e034-e03d-484e-b396-7bb5eb5a3b55",
   "metadata": {},
   "source": [
    "## The optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "7d83ce75-20f3-4b98-bc97-b5b9da86ca20",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 1e-2\n",
    "def update_for_sample(params, x, y):\n",
    "    grads = grad(loss_for_sample)(params, x, y)\n",
    "    return [(w - step_size * dw, b - step_size *db) for (w,b),(dw,db) in zip(params, grads)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "57d662f7-810c-47e8-b133-787b01a1b644",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network_parameters = update_for_sample(neural_network_parameters, np.zeros(50), np.array([1,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cccfb60-17f2-4412-939c-4e8170360e48",
   "metadata": {},
   "source": [
    "## The training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "f0092716-fb0d-4119-9c03-b111f5827da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial prediction: \n",
      "[0.7025618 0.7088518]\n",
      "After training: \n",
      "[0.2398114 0.8432371]\n"
     ]
    }
   ],
   "source": [
    "layer_sizes = [50, 10, 2]\n",
    "neural_network_parameters = initialize_network_params(layer_sizes)\n",
    "\n",
    "print(\"Initial prediction: \")\n",
    "print(predict_sample(neural_network_parameters, np.zeros(50)))\n",
    "\n",
    "for epoch in range(500):\n",
    "    # Update the neural network parameters, so that for input 'np.zeros(50)' the output becomes '[0,1]'\n",
    "    neural_network_parameters = update_for_sample(neural_network_parameters, np.zeros(50), np.array([0,1]))\n",
    "    \n",
    "print(\"After training: \")\n",
    "print(predict_sample(neural_network_parameters, np.zeros(50)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0510dd22-0180-4e61-81cc-813d7984f9c4",
   "metadata": {},
   "source": [
    "### If we now want to predict for many samples, we **could** do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "221df96c-ee18-4366-80e1-6317537a6c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.765141\n"
     ]
    }
   ],
   "source": [
    "# Generate 10 random samples of size 50\n",
    "all_samples = np.random.rand(10,50)\n",
    "# For demonstration purposes, let's have the same target for all samples\n",
    "target = np.array([1,0])\n",
    "\n",
    "total_loss = 0\n",
    "for sample in all_samples:\n",
    "    total_loss += loss_for_sample(neural_network_parameters, sample, target)\n",
    "    \n",
    "print(total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e473fe20-94a9-4723-8f7d-9a9290aeea5c",
   "metadata": {},
   "source": [
    "#### But JAX can do this much faster! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "3599190f-bbf3-4ec9-9762-823ff1606922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a 'vectorized' version of predict_sample, using 'vmap'\n",
    "# Here we tell JAX that the index to be vectorized over is the first (in_axis = 0), and that it \n",
    "#   should also put that vectorized result as the first index in the output\n",
    "predict = vmap(predict_sample, in_axes=(None,0), out_axes=0)\n",
    "\n",
    "# Now we (re-)define the loss function to use this new vectorized predict function\n",
    "def loss(params, samples, targets):\n",
    "    pred = predict(params, samples)\n",
    "    return jnp.mean( (pred - targets)**2 )\n",
    "\n",
    "# And the same for the update function\n",
    "step_size = 1e-2\n",
    "#@jit\n",
    "def update(params, x, y):\n",
    "    grads = grad(loss)(params, x, y)\n",
    "    return [(w - step_size * dw, b - step_size *db) for (w,b),(dw,db) in zip(params, grads)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "6e8cdef2-3bb2-423d-9d30-df215d5ff398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial prediction: \n",
      "[[0.7331598  0.9061516 ]\n",
      " [0.8618607  0.79652697]\n",
      " [0.62596804 0.81051296]\n",
      " [0.8639208  0.88325244]\n",
      " [0.7379976  0.9311364 ]\n",
      " [0.5626366  0.7117155 ]\n",
      " [0.8775297  0.8445624 ]\n",
      " [0.85660243 0.82235706]\n",
      " [0.86117375 0.8429931 ]\n",
      " [0.85192144 0.91011536]]\n",
      "After training: \n",
      "[[0.14645067 0.9381032 ]\n",
      " [0.30671868 0.8825794 ]\n",
      " [0.12380596 0.8912052 ]\n",
      " [0.22043103 0.9405608 ]\n",
      " [0.16109806 0.95768106]\n",
      " [0.10426618 0.8038362 ]\n",
      " [0.31655475 0.9157887 ]\n",
      " [0.23097222 0.90807724]\n",
      " [0.24089806 0.9044562 ]\n",
      " [0.25836465 0.94957983]]\n"
     ]
    }
   ],
   "source": [
    "all_samples = np.random.rand(10,50)\n",
    "targets = np.array([[0,1] for i in range(10)])\n",
    "\n",
    "layer_sizes = [50, 10, 2]\n",
    "neural_network_parameters = initialize_network_params(layer_sizes)\n",
    "\n",
    "print(\"Initial prediction: \")\n",
    "print(predict(neural_network_parameters, all_samples))\n",
    "\n",
    "for epoch in range(500):\n",
    "    neural_network_parameters = update(neural_network_parameters, all_samples, targets)\n",
    "    \n",
    "print(\"After training: \")\n",
    "print(predict(neural_network_parameters, all_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b66a3e-0b9a-4761-bb9a-283c2e442c8e",
   "metadata": {},
   "source": [
    "# Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d124f6c-b75d-49b6-a758-d8fb85be7cea",
   "metadata": {},
   "source": [
    "Instead of defining the model parameters for this network ourselves, the module `Flax` is very useful for defining neural networks. Especially once you would like to build more complex ones (convolutional layers, for example), it is a useful module to have on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773c042a-7f27-41d0-82a2-25796c8d7530",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
